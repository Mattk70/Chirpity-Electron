<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Chirpity Nocmig Settings</title>
</head>
<body>

<table class="table table-hover p-1">
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Predictions</h5></td>
    </tr>
    <tr>
        <th>Set Threshold</th>
        <td>This setting determines the minimum confidence level required for the model to report a detection.
            Increasing the value reduces false positives but increases the risk of missing genuine calls.
            A value around 50% provides a good balance between detecting genuine calls and minimizing false positives.
        </td>
    </tr>
    <tr>
        <th>Search for</th>
        <td><p><b>Local Birds</b>. Exclude birds unlikely to be found in your location.</p>
            <p><b>Nocturnal Birds</b>. Just report detections relating to these species' calls (song detections are
            excluded).</p>
            <p><b>All birds</b>. Include birdsong as well as calls, also includes species not known to call at night.
            </p>
            <p><b>Everything</b>. In addition to birds, show non-bird detections including segments that were considered noise.
            </ul>
            <p>If you wish to see the full list of the 320 species Chirpity <i>Nocmig</i> was trained on, just explore the list
                offered when correcting a prediction.</p>
        </td>
    </tr>
    <tr>
        <th>Nocmig Mode</th>
        <td>
            Only search for detections at night. Chirpity calculates the end and start of civil twilight for the dates
            of the files and the location that is set.
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Location</h5></td>
    </tr>
    <tr>
        <th>Location</th>
        <td>
            <figure class="figure float-end m-3">
                <img src="Help/amend file.png"
                    alt="The context menu accessed from the filename contains options to amend the file's start time and the recording location"
                    class="rounded figure-img float-end img-fluid">
                <figcaption class="figure-caption text-muted text-end">File name context menu.</figcaption>
            </figure>
            Set the default location to use for calculating the start and end of civil twilight. This setting can be overriden for individual files by assigning a custom location in the filename context menu.
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Spectrogram</h5></td>
    </tr>
    <tr>
        <td><b>Colourmap</b></td>
        <td>Choose the colour map for the spectrogram display</td>
    </tr>
    <tr>
        <th>Timeline</th>
        <td>The spectrogram timeline has two modes:
            <ul>
                <li>
                    <b>Timecode</b> displays the time elapsed from the beginning of the file.
                </li>
                <li>
                    <b>Time of Day</b> relies on file timestamps to determine the actual time of detected calls.
                    If a file's timestamp does not reflect the recording time, the readonig will be inaccurate.
                    To edit the start time of the current file, set the desired date and time using the filename context menu.
                </li>
            </ul>
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>System</h5></td>
    </tr>
    <tr>
        <th>Backend</th>
        <td>Choose how predictions are calculated on you computer.
            <ul>
                <li>
                    <b>CPU</b> will use the CPU for predictions, this is generally faster if you have an integrated
                    graphics card.
                </li>
                <li>
                    <b>GPU</b> will use the graphics card. If you have a dedicated graphics card, this will typically be
                    significantly faster.
                </li>
            </ul>
        </td>
    </tr>
    <th>Model</th>
    <td>Choose the model to use for prediction.
        <ul>
            <li>
                <b>Chirpity</b> will use the native Chirpity model for predictions.
            </li>
            <li>
                <b>BirdNET</b> will use the <a href="https://github.com/kahst/BirdNET-Analyzer" target="_blank">BirdNET</a> model developed by Stefan Kahl et al. from the K. Lisa Yang Center for Conservation Bioacoustics
            </li>
        </ul>
    </td>
</tr>
    <tr>
        <th>Threads</th>
        <td>This setting allows you to select the number of threads to use for predictions.
            When using the CPU backend, the number of threads is automatically set to match the number of CPU cores available on the computer.
            By default, the GPU backend uses one thread. Adjusting this setting, along with the batch size, can optimize the speed of predictions.
        </td>
    </tr>
    <tr>
        <th>Batch Size</th>
        <td>This setting determines the number of three-second audio chunks to process each time a prediction is requested.
            Larger values lead to faster processing, especially on long files.
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-warning"><h5>Experimental Features</h5></td>
    </tr>
    <tr>
        <th>Context Mode</th>
        <td> In this mode, Chirpity will use the surrounding context when making predictions. This helps mitigate
            against false positive detections.
        </td>
    </tr>
        <th>SNR filter</th>
        <td>The SNR (Signal to Noise Ratio) filter can only be enabled when using the CPU backend. When enabled, Chirpity will disregard audio segments with no distinct sound event.
            A stronger signal is required for a prediction to be attempted when higher signal-to-noise values are set.
            The purpose is to deliver significant speed gains, however, the setting may cause Chirpity to miss quieter, more distant calls.
        </td>
    </tr>
    <tr>
        <th>High Pass filter</th>
        <td> This applies a filter to the audio, removing the sound below the frequency selected. 
            Intended primarily for recordings made in in urban settings, this is desirable to compensate for strong low-frequency noise which is not present in the training data.
        </td>
    </tr>
    <tr>
        <th>Low Shelf filter</th>
        <td> This applies an audio filter similar to the High Pass filter, however, rather than simply remove noise, it reduces the volume of low frequency noise. 
            You can set the threshold frequency, and the strength of the filter to apply (Attenuation).
            Also intended for recordings made in in urban settings, this helps tune the audio to the noise profile of the training data.
        </td>
    </tr>
</table>

</body>
</html>