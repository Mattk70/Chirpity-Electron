<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Chirpity Nocmig Settings</title>
</head>
<body>

<table class="table table-hover p-1">
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Detections</h5></td>
    </tr>
    <tr>
    <th>Model</th>
        <td>Choose the model to use for detection.
            <ul>
                <li>
                    <b>Chirpity</b> will use the native Chirpity model for analysis.
                </li>
                <li>
                    <b>BirdNET</b> will use the <a href="https://github.com/kahst/BirdNET-Analyzer" target="_blank">BirdNET</a> model developed by Stefan Kahl et al. from the K. Lisa Yang Center for Conservation Bioacoustics
                </li>
            </ul>
        </td>
    </tr>
    <tr>
        <th>Confidence Threshold</th>
        <td>This setting determines the minimum confidence level required for the model to report a detection.
            Increasing the value reduces false positives but increases the risk of missing genuine calls.
            <b>N.B.</b> Confidence can be adjusted at any time. The results are updated even after analysis.
        </td>
    </tr>
    <tr>
        <th>List</th>
        <td><p><b>Local Birds</b>. Exclude birds unlikely to be found in your location.</p>
            <p style="padding-left: 2em">With this option selected, an additional panel appears. The <b>Threshold</b> value represents the eBird checklist frequency. 
                    So, a value of 0.03 means birds that are predicted to occur in less than 3% of eBird checklists in the area are excluded. 
                    If you also check "Use Week", it excludes birds not expected at the time of year the recording was made - which is read from the file's timestamp.
                    <br /> <b>N.B.</b> Currently, a limitation to the week specific filters is that the summary of detections will use the 
                    list from the latest file in a batch of files. 
                    For example, if you analyse files from April 22, October 23 and February 24 in a batch, the list for February 24 will be used for the summary.
                </p>
            <p><b>Nocturnal Birds</b>. This will exclude detections of bird song and the calls of species which do not typically vocalise during the night. 
                When you enable "<b>Use Location settings</b>" for the BirdNET model, the list will comprise the birds on the <b>Local Birds</b> list, excluding those 
                which do not call at night.</p>
            <p><b>Birds</b>. Include detections for all birds, excluding non-avian classes.
            </p>
            <p><b>Everything</b>. In addition to all bird species, show non-bird detections including segments that were considered noise.</p>
            <p><b>Custom</b>. Provide a list for the model to use. Custom lists allow you to:</p>
                <ol>
                    <li>Precisely define the detections you would like Chirpity to report on</li>
                    <li>Search only for a specific species</li>
                </ol>
                You may use a different custom list for both BirdNET and Chirpity models. The format for a 
                custom list file is "scientific name_common name", with each species on a new line. <b>Importantly, the custom list needs to use labels in your selected language.</b> You can export a starting
                list in the correct format from the Help menu, using the "<i>What species are detected?</i>" link. 
        </td>
    </tr>
    <tr>
        <th>Only analyse night time periods</th>
        <td>
            Only search for detections at night. Chirpity calculates the end and start of civil twilight from the timestamps of your audio files using the location you have set. If your recording
            spans both daylight and night time periods, the day periods will be skipped. If you are only interested in nocturnal calls this has two benefits: 
            <ol>
                <li>There will be fewer false positives, since both models make more mistakes when many species vocalise at once (e.g. during the dawn chorus)</li>
                <li>The analysis will complete faster, since it ignores any daytime period</li>
            </ol>
        </td>
    </tr>
    <tr>
        <th>Show Species IUCN Red List status in the summary</th>
        <td>
            Display the global Red List status of the species in the summary table, as assessed by the <a href="https://www.iucnredlist.org/" target="_blank">IUCN</a>  There are 7 categories:
            <ol>
                <li>Least Concern (LC)</li>
                <li>Near Threatened (NT)</li>
                <li>Vulnerable (VU)</li>
                <li>Endangered (EN)</li>
                <li>Critically ENdangered (CR)</li>
                <li>Extinct in the Wild</li>
                <li>Extinct</li>
            </ol>
            If you click the icon, it will open the assessment page with the species' range and details of the assessment in your web browser. The data is sourced from:
            <cite>
                IUCN 2024. IUCN Red List of Threatened Species. Version 2024-1
            </cite>
        </td>
    </tr>
    <tr>
        <th>Clear reference call cache</th>
        <td>
            The species' comparison metadata that determine what you see when you select "Compare with Reference Calls" on a context menu are saved to disk. If you clear the cache,
            the saved data are deleted, and species data will be re-requested from the Xeno-Canto website when you next ask for a comparison. This may be useful if a reference file 
            is removed from the site, or if you would like to update the selection of calls.
        </td>
    </tr>
    <tr>
        <th>Default Location</th>
        <td>
            <figure class="figure float-end m-3">
                <img src="Help/amend file.png"
                    alt="The context menu accessed from the filename contains options to amend the file's start time and the recording location"
                    class="rounded figure-img float-end img-fluid">
                <figcaption class="figure-caption text-muted text-end">File name context menu.</figcaption>
            </figure>
            Set the default location to use for calculating the start and end of civil twilight and also generating your <b>Local Birds</b> list. This setting can be overridden for individual
            files by assigning a custom location in the filename context menu.
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>System</h5></td>
    </tr>
    <tr>
        <th>Language</th>
        <td>
            Choose the language for the "common name" labels, where translations exist. The translated labels have been obtained from <a href="https://ebird.org/home" target="_blank">eBird</a>. 
        </td>
    </tr>
    <tr>
        <th>Backend</th>
        <td>This option is only visible when using the Chirpity model. Choose how predictions are calculated on you computer.
            <ul>
                <li>
                    <b>CPU</b> will use the CPU for predictions, this is generally faster if you have an integrated
                    graphics card.
                </li>
                <li>
                    <b>WebGL</b> will use the graphics card. If you have a dedicated graphics card, this will typically be
                    significantly faster.
                </li>
                <li>
                    <b>WebGPU</b> This employs a new technology and will also use graphics processors. It is similar to WebGL, 
                    but is known to speed up the processing times on Macs, unlike WebGL. WebGPU uses more memory than WebGL, and 
                    if the threads or batch size values are set too high, Chirpity may run out of memory. If this happens 
                    the spectrogram will disappear from the screen. Use a lower value for threads and / or batch size.
                </li>
            </ul>
        </td>
    </tr>

    <tr>
        <th>Threads</th>
        <td>This setting allows you to select the number of threads to use for predictions.
            When using the CPU backend, the number of threads is automatically set to match the number of CPU cores available on the computer.
            By default, the GPU backend uses two threads. Adjusting this setting, along with the batch size, can increase the speed of processing.
        </td>
    </tr>
    <tr>
        <th>Batch Size</th>
        <td>This setting determines the number of three-second audio chunks to process for each model request.
            Larger values may lead to faster processing, especially on long files, although too large a value will reduce the processing speed and may even cause memory issues. 
            The optimal value may also differ depending on the file format being analysed.
        </td>
    </tr>
    <tr>
        <th>Enable analysis completion notifications</th>
        <td>
            This is useful if you would like to run Chirpity analysis in the background, 
            or with the window minimised. A system alert will notify you when the analysis completes.
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Audio Preferences</h5></td>
    </tr>
    <tr>
        <td><b>Volume Adjustment</b></td>
        <td>If your recordings are very quiet, you can increase the loudness of the audio by increasing the gain. The volume of audio can be increased by up to 50 decibels.</td>
    </tr>
    <tr>
        <td><b>Normalise audio</b></td>
        <td>
            If enabled, the levels in the audio file will be normalised. In simple terms, this will maximise the volume range between the quietest and loudest sounds. 
            The effect will ensure all audio plays at a similar volume, and vocalisations in quiet audio files will be easier to hear.
        </td>
    </tr>
    <tr>
        <th>High Pass filter</th>
        <td> This filter removes the sound below the frequency selected. 
            Intended primarily for recordings made in in urban settings, this suppresses low-frequency hum.
        </td>
    </tr>
    <tr>
        <th>Low Shelf filter</th>
        <td> This filter is similar to the High Pass filter. However, rather than simply remove noise, it reduces the volume of low frequency noise. 
            The advantage of a low shelf filter is that you can reduce the hum, whilst still being able to hear species which have low frequency calls.
            You can set the threshold frequency, and the strength of the filter to apply (Attenuation).
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Audio Export</h5></td>
    </tr>
    <tr>
        <td><b>Format and Bitrate</b></td>
        <td>Choose from lossless or lossy formats for the audio clips you export from Chirpity.</td>
    </tr>
    <tr>
        <td><b>Convert to mono</b></td>
        <td>Combine stereo tracks to a single channel. This will result in smaller file sizes.</td>
    </tr>
    <tr>
        <th>Decorators</th>
        <td>These two options can be used to:
            <ul>
                <li>
                    <b>Pad:</b> Add two seconds to the beginning and end of the audio selected for export
                </li>
                <li>
                    <b>Fade:</b> Apply a fade effect to the beginning and end of your exported files.
                </li>
            </ul>
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Audio Library</h5></td>
    </tr>
    <tr>
        <td><b>Add to Library on Save</b></td>
        <td>When you save a set of results to the archive database, the associated audio files will be converted to the library format and saved in the archive location.</td>
    </tr>
    <tr>
        <td><b>Crop library audio to night time periods</b></td>
        <td>This will crop the start or end sections of a file to remove the audio that was recorded during daylight. Specifically, before the end of Civil Twilight in the evening and after the end of Civil Twilight in the morning. 
            Those periods are set according to the file's location settings.</td>
    </tr>
    <tr>
        <td><b>Library Location</b></td>
        <td>Select a folder in which to store the audio library. The files will be organised according to the following structure:
            <pre>
        &lt;Your chosen location&gt; / Recording site / Year / Month / filename</pre>
        <p>For example: <b>D:\Vögel\56075, Karthäuserhofgelände\2024\Juli\20240704_0130.flac</b></p>
        </td>
    </tr>
    <tr>
        <th>Library Format</th>
        <td>The library can store your audio in a lossy or lossless format.
            <ul>
                <li>
                    <b>Lossy:</b> Audio is converted to Ogg Vorbis. This is the recommended option. The audio will be virtually indistinguishable from the original in the application - both to the model and to the human ear.
                    The file size will be dramatically reduced - to the extent that a full 24 hours of recordings will require about 1 Gigabyte of storage. 
                </li>
                <li>
                    <b>Lossless:</b> If the lossless option is selected, the audio fidelity (bitrate, channels and sample rate) will be identical to the original file - even WAV files. By using the FLAC format, the archived files will
                    have roughly half the size of their WAV equivalents. 
                </li>
            </ul>
        </td>
    </tr>
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Spectrogram Preferences</h5></td>
    </tr>
    <tr>
        <td><b>Colourmap</b></td>
        <td>Choose a colour theme for the spectrogram display, or create your own. If you select 'custom', you will have the option to set the colours for peak, mid and quiet sounds according
            to personal preference. You can also adjust the mid-point position: with a value of 0 or 1, the Spectrogram will be two-tone. Values in between will blend the three colours. 
            If you set the Mid colour the same as one of the others, you will be able to adjust the contrast in the spectrogram using Mid Position adjustments.
            <p>In combination with audio filter adjustments, a custom colourmap allows you to enhance the contrast / visibility of calls using the colours of your choice.</p>
        </td>
    </tr>
    <tr>
        <td><b>Window Function</b></td>
        <td>A variety of windowing functions are available for the spectrogram display. Each has slightly different characteristics, so changing the window function may also enhance the 
            appearance of the calls in the display.
        </td>
    </tr>
    <tr>
        <th>Timeline</th>
        <td>The spectrogram timeline has two modes:
            <ul>
                <li>
                    <b>Timecode</b> displays the time elapsed from the beginning of the file.
                </li>
                <li>
                    <b>Time of Day</b> relies on file timestamps to determine the actual time of detected calls.
                    If a file's timestamp does not reflect the recording time, the reading will be inaccurate.
                    To edit the start time of the current file, set the desired date and time using the filename context menu.
                </li>
            </ul>
        </td>
    </tr>
 
    <tr>
        <td colspan="2" class="text-center text-bg-light"><h5>Advanced</h5></td>
    </tr>
    <tr>
        <th>Send Filtered Audio for Analysis</th>
        <td> 
            By default, the filter settings in the Audio Preferences are just used to modify the audio in the application interface. If you enable this setting, 
            the modified audio will be used for analysis. This is usually a bad idea, as it impairs the accuracy of the models in most situations. However, if your 
            recordings have a considerable amount of low frequency noise, it <i>may</i> be that modifying the audio using these filters will improve the models' ability to 
            make accurate detections.
        </td>
    </tr>
    <tr>
        <th>Context Mode</th>
        <td> This mode is only available for the native Chirpity model. When enabled, the model will use the surrounding context when making predictions. This helps mitigate
            against false positive detections.
        </td>
    </tr>
    <tr>
        <th>SNR filter</th>
        <td>This setting is also only available for the native Chirpity model. The SNR (Signal to Noise Ratio) filter can only be enabled when using the CPU backend. 
            When enabled, Chirpity will disregard audio segments with no distinct sound event.
            A stronger signal is required for a prediction to be attempted when higher signal-to-noise values are set.
            The purpose is to deliver significant speed gains, however, the setting may cause Chirpity to miss quieter, more distant calls.
        </td>
    </tr>
    <tr>
        <th>Debug mode</th>
        <td>
            If you have encountered an issue while using Chirpity, you can enable debug mode. When you change this setting, you will need to quit and relaunch the application 
            for the change to take effect. When launched in debug mode, two windows will open, and each will print debugging information to a console on the right of the window.
            This is <b>extremely </b> useful if you want to report a bug - as you can share a screenshot of any errors that appear (these will show up in red in the console).
        </td>
    </tr>
    <tr>
        <th>Opt out of usage analytics</th>
        <td>
            Chirpity sends usage information anonymously to an analytics server. This information is used to help understand how people use Chirpity, and try to identify any bugs
            or errors. Both help improve the software and prioritise changes for future releases. If you would prefer that Chirpity did not send any usage data, you can disable it here. 
        </td>
    </tr>
</table>

</body>
</html>